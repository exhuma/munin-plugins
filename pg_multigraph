#!/usr/bin/env python

from __future__ import print_function
from collections import namedtuple
from os import getenv
from psycopg2 import connect  # TODO <- munin autoconfig
from textwrap import dedent
import argparse
import logging
import re

LOG = logging.getLogger(__name__)


INVALID_CHARS = re.compile(r'[^a-zA-Z0-9_]')
ConnectionCounter = namedtuple(
    'ConnectionCounter',
    'username idle idle_tx unknown query_running waiting')
Lock = namedtuple('Lock', 'mode, granted')
GraphedValue = namedtuple('GraphedValue', 'name, label, doc')
DbHealth = namedtuple('DbHealth', 'dbname vacuum_age analyze_age')


def construct_dsn(dbname, user, password='', host='', port=0):
    elements = [
        'dbname=%s' % dbname,
        'user=%s' % user
    ]
    if password:
        elements.append('password=%s' % password)
    if host:
        elements.append('host=%s' % host)
    if port:
        elements.append('port=%d' % port)

    return ' '.join(elements)


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('action', nargs='?',
                        help='The munin action to perform',
                        default='fetch')
    return parser.parse_args()


class PostgresPlugin(object):

    def __init__(self, connection, user, password, host, port):
        self.connection = connection
        self.user = user
        self.password = password
        self.host = host
        self.port = port

    def fetch(self):
        print('multigraph %s' % self.graph_name)

    def config(self):
        print('multigraph %s' % self.graph_name)
        print('graph_category postgresql_multi')

    @property
    def graph_name(self):
        return 'pgmg_%s' % self.NAME


class Connections(PostgresPlugin):

    NAME = 'connections'

    def all_connections(self):
        # Fetch the current username of the connection
        cursor = self.connection.cursor()
        cursor.execute('SELECT CURRENT_USER')
        whoami = cursor.fetchone()[0]
        cursor.close()

        query = dedent(
            '''\
            WITH users AS (SELECT usename FROM pg_user),
            conntype AS (SELECT u.usename, act.waiting,
                current_query
                FROM users u
                LEFT JOIN pg_stat_activity act USING (usename))
            SELECT
                usename,
                COUNT(CASE WHEN current_query='<IDLE>'
                    THEN 1 END) AS idle,
                COUNT(CASE WHEN current_query='<IDLE> in transaction'
                    THEN 1 END) AS idle_tx,
                COUNT(CASE WHEN current_query='<insufficient privilege>'
                    THEN 1 END) AS unknown,
                COUNT(CASE WHEN current_query NOT IN (
                    '<IDLE>',
                    '<IDLE> in transaction',
                    '<insufficient privilege>')
                    THEN 1 END) AS query_running,
                COUNT(CASE WHEN waiting THEN 1 END) AS waiting
            FROM conntype
            GROUP BY usename
            ORDER BY usename;''')
        cursor = self.connection.cursor()
        cursor.execute(query)
        output = []
        for username, idle, idle_tx, unknown, query_running, waiting in cursor:
            if username == whoami:  # Subtract our own active query
                query_running = query_running - 1
            output.append(ConnectionCounter(username, idle, idle_tx, unknown,
                                            query_running, waiting))
        cursor.close()
        return output

    def fetch(self):
        super(Connections, self).fetch()
        conns = self.all_connections()
        sums = {
            'idle': sum([conn.idle for conn in conns]),
            'idle_transaction': sum([conn.idle_tx for conn in conns]),
            'unknown': sum([conn.unknown for conn in conns]),
            'query_running': sum([conn.query_running for conn in conns]),
            'waiting': sum([conn.waiting for conn in conns]),
        }

        print('idle.value %d' % sums['idle'])
        print('idle_transaction.value %d' % sums['idle_transaction'])
        print('unknown.value %d' % sums['unknown'])
        print('query_running.value %d' % sums['query_running'])
        print('waiting.value %d' % sums['waiting'])

        # print values for the each subgraph
        for subgraph in conns:
            print('multigraph %s.%s' % (
                self.graph_name,
                INVALID_CHARS.sub('_', subgraph.username)))
            print('idle.value %d' % subgraph.idle)
            print('idle_transaction.value %d' % subgraph.idle_tx)
            print('unknown.value %d' % subgraph.unknown)
            print('query_running.value %d' % subgraph.query_running)
            print('waiting.value %d' % subgraph.waiting)

    def config(self):
        super(Connections, self).config()
        # We want the main and subgraph to use the same config. So we store it
        # as a variable.
        common_config_block = dedent(
            '''\
            graph_args --base 1000
            graph_vlabel connections
            graph_order waiting query_running idle idle_transaction unknown
            graph_printf %3.0lf
            waiting.label Waiting for lock
            waiting.draw AREA
            query_running.label Active query
            query_running.draw STACK
            idle.label Idle connections
            idle.draw STACK
            idle_transaction.label Idle transaction
            idle_transaction.draw STACK
            unknown.label unknown
            unknown.draw STACK
            ''')

        conns = self.all_connections()

        print('graph_title Global PostgreSQL Connections')
        print('graph_info Shows an overview of connections and their type on '
              'the PostgreSQL cluster.')

        print(common_config_block)
        for subgraph in conns:
            clean_username = INVALID_CHARS.sub('_', subgraph.username)
            print('multigraph %s.%s' % (self.graph_name, clean_username))
            print('graph_title PostgreSQL Connections for %s' %
                  subgraph.username)
            print(common_config_block)


class TableHealth(PostgresPlugin):

    NAME = 'table_health'

    def get_stats(self):
        # we need to get stats for each DB. We need to create new connections
        # for each.
        cursor = self.connection.cursor()
        cursor.execute('SELECT datname FROM pg_database')
        dbnames = [row[0] for row in cursor]
        cursor.close()

        # Fetch stats for each DB
        stats_query = dedent(
            '''\
            SELECT
                schemaname || '.' || relname AS table_name,
                EXTRACT(EPOCH FROM (NOW() -
                        GREATEST(last_vacuum, last_autovacuum)))
                    AS vacuum_age,
                EXTRACT(EPOCH FROM (NOW() -
                        GREATEST(last_analyze, last_autoanalyze)))
                    AS analyze_age
            FROM pg_stat_user_tables ;
            ''')

        stats = {}
        for dbname in dbnames:
            try:
                localcon = connect(
                    construct_dsn(dbname,
                                  self.user,
                                  self.password,
                                  self.host,
                                  self.port))
            except Exception as exc:
                LOG.error(exc)
                stats[dbname] = []
                continue

            cursor = localcon.cursor()
            cursor.execute(stats_query)
            dbstats = []
            for tablename, vacuum_age, analyze_age in cursor:
                dbstats.append(DbHealth(tablename, vacuum_age, analyze_age))
            stats[dbname] = dbstats
            cursor.close()
            localcon.close()
        return stats

    def fetch(self):
        super(TableHealth, self).fetch()
        allstats = self.get_stats()

        # collect global stats
        oldest_vacuum = None
        oldest_analyze = None
        for dbname, stats in allstats.items():
            for tablestats in stats:
                oldest_vacuum = max(oldest_vacuum, tablestats.vacuum_age)
                oldest_analyze = max(oldest_analyze, tablestats.analyze_age)

        if all([oldest_analyze, oldest_vacuum]):
            print('oldest_vacuum.value %f' % oldest_vacuum)
            print('oldest_analyze.value %f' % oldest_analyze)

        # TODO # print values for the each subgraph
        # TODO for subgraph in conns:
        # TODO     print('multigraph %s.%s' % (self.graph_name,
        # TODO                                 INVALID_CHARS.sub('_', subgraph.username)))
        # TODO     print('idle.value %d' % subgraph.idle)
        # TODO     print('idle_transaction.value %d' % subgraph.idle_tx)
        # TODO     print('unknown.value %d' % subgraph.unknown)
        # TODO     print('query_running.value %d' % subgraph.query_running)
        # TODO     print('waiting.value %d' % subgraph.waiting)

    def config(self):
        super(TableHealth, self).config()
        # We want the main and subgraph to use the same config. So we store it
        # as a variable.
        common_config_block = dedent(
            '''\
            graph_args --base 1000
            graph_vlabel Age (seconds)
            oldest_vacuum.label Oldest Vacuum Age
            oldest_analyze.label Oldest Analyze Age
            ''')

        print('graph_title Global PostgreSQL Table Health')
        print(common_config_block)

        # TODO for subgraph in conns:
        # TODO     clean_username = INVALID_CHARS.sub('_', subgraph.username)
        # TODO     print('multigraph %s.%s' % (self.graph_name, clean_username))
        # TODO     print('graph_title PostgreSQL Connections for %s' % subgraph.username)
        # TODO     print(common_config_block)


class Sizes(PostgresPlugin):

    NAME = 'sizes'

    def get_stats(self):
        cursor = self.connection.cursor()
        cursor.execute('SELECT datname, pg_database_size(datname) '
                       'FROM pg_database WHERE datistemplate=false')
        sizes = cursor.fetchall()
        cursor.close()
        return {row[0]: row[1] for row in sizes}

    def fetch(self):
        super(Sizes, self).fetch()
        stats = self.get_stats()

        for dbname, value in stats.items():
            print('%s.value %s' % (INVALID_CHARS.sub('_', dbname), value))

        for dbname, value in stats.items():
            print('multigraph %s.%s' % (self.graph_name, dbname))
            print('size.value %s' % value)

    def config(self):
        super(Sizes, self).config()
        stats = self.get_stats()
        print(dedent(
            '''\
            graph_title PostgreSQL Database Sizes
            graph_args --base 1024
            graph_vlabel Size in Bytes
            '''))

        first_graph = True
        for dbname in sorted(stats):
            print(dedent(
                '''\
                {clean_name}.info Size in Bytes for database {clean_name}
                {clean_name}.label {raw_name}
                {clean_name}.draw {style}
                {clean_name}.min 0
                '''.format(raw_name=dbname,
                           clean_name=INVALID_CHARS.sub('_', dbname),
                           style='AREA' if first_graph else 'STACK')))
            first_graph = False

        # Scale each graph relative to the biggest DB
        upper_limit = max(stats.values())
        template = dedent(
            '''\
            multigraph {graph_name}.{dbname}
            graph_title Size for {dbname}
            graph_args --base 1024 --upper-limit {upper_limit}
            graph_order size
            size.min 0
            size.draw AREA
            size.label Size (in Bytes)
            ''')
        for dbname, value in stats.items():
            print(template.format(graph_name=self.graph_name,
                                  dbname=dbname,
                                  upper_limit=upper_limit))


class Locks(PostgresPlugin):

    NAME = 'locks'
    COLORS = [
        ('ff0000', 'ff8080'),
        ('ffbf00', 'ffdf80'),
        ('80ff00', 'bfff80'),
        ('00ff40', '80ff9f'),
        ('00ffff', '80ffff'),
        ('0040ff', '809fff'),
        ('7f00ff', 'bf80ff'),
        ('ff00bf', 'ff80df'),
    ]
    ACCEPTED_LOCK_NAMES = {
        GraphedValue('accesssharelock', 'Access share', ''),
        GraphedValue('rowsharelock', 'Row share', ''),
        GraphedValue('rowexclusivelock', 'Row excl.', ''),
        GraphedValue('shareupdateexclusivelock', 'Share upd. excl.', ''),
        GraphedValue('sharelock', 'Share', ''),
        GraphedValue('sharerowexclusivelock', 'Share row excl.', ''),
        GraphedValue('exclusivelock', 'Exclusive', ''),
        GraphedValue('accessexclusivelock', 'Access excl.', ''),
    }

    def _graph_config(self):
        first_graph = True
        for i, lock_info in enumerate(sorted(self.ACCEPTED_LOCK_NAMES)):
            waiting_color, granted_color = self.COLORS[i]
            print(dedent(
                '''\
                {lock.name}_granted.label {lock.label} (granted)
                {lock.name}_granted.draw {style}
                {lock.name}_granted.min 0
                {lock.name}_granted.colour {gcolour}
                {lock.name}_waiting.label {lock.label} (waiting)
                {lock.name}_waiting.draw STACK
                {lock.name}_waiting.min 0
                {lock.name}_waiting.colour {wcolour}
                '''.format(lock=lock_info,
                           style='AREA' if first_graph else 'STACK',
                           gcolour=granted_color,
                           wcolour=waiting_color)))
            first_graph = False

    def get_stats(self):
        query = dedent(
            '''\
            SELECT
                db.datname,
                LOWER(mode),
                locktype,
                granted,
                COUNT(mode)
            FROM pg_database db
            FULL OUTER JOIN pg_locks lck ON (db.oid=lck.database)
            GROUP BY db.datname, mode, locktype, granted;
            ''')
        cursor = self.connection.cursor()
        cursor.execute(query)
        locks = cursor.fetchall()
        cursor.close()
        output = {}
        for dbname, lockmode, locktype, granted, count in locks:
            if dbname is None:
                # locks without related DB, are "global" locks
                dbname = '__pg__database__'

            dblocks = output.setdefault(dbname, {})
            dblocks[Lock(lockmode, granted)] = count

        # The above query only returns rows for databases with actual
        # waiting/granted locks. We always want all DBs to be monitored though.
        # DBs which don't have locks should report the value `0`. This prevents
        # NaN values ("holes") in munin.
        cursor = self.connection.cursor()
        cursor.execute('SELECT datname FROM pg_database '
                       'WHERE datistemplate=false')
        for row in cursor.fetchall():
            output.setdefault(row[0], {})
        cursor.close()
        return output

    def fetch(self):
        super(Locks, self).fetch()
        stats = self.get_stats()

        sums = {}
        for row in stats.values():
            for lock_info in self.ACCEPTED_LOCK_NAMES:
                granted_lock = Lock(lock_info.name, True)
                waiting_lock = Lock(lock_info.name, False)
                granted_value = sums.setdefault(granted_lock, 0)
                granted_value += row.get(granted_lock, 0)
                waiting_value = sums.setdefault(waiting_lock, 0)
                waiting_value += row.get(waiting_lock, 0)
                sums[granted_lock] = granted_value
                sums[waiting_lock] = waiting_value

        for lock, value in sums.items():
            print('%s_%s.value %s' % (lock.mode,
                                      'granted' if lock.granted else 'waiting',
                                      value))

        for dbname, values in sorted(stats.items()):
            print('multigraph %s.%s' % (self.graph_name, dbname))
            for lock_info in self.ACCEPTED_LOCK_NAMES:
                granted_lock = Lock(lock_info.name, True)
                waiting_lock = Lock(lock_info.name, False)
                print('%s_granted.value %d' % (lock_info.name,
                                               values.get(granted_lock, 0)))
                print('%s_waiting.value %d' % (lock_info.name,
                                               values.get(waiting_lock, 0)))

    def config(self):
        super(Locks, self).config()
        stats = self.get_stats()
        print(dedent(
            '''\
            graph_title PostgreSQL Locks
            graph_args --base 1000
            graph_vlabel Number of locks
            graph_printf %3.0lf
            '''))

        self._graph_config()

        for dbname, value in stats.items():
            print('multigraph %s.%s' % (self.graph_name, dbname))
            print('graph_title Locks for %s' % dbname)
            self._graph_config()


def main(action):
    dbname = getenv('PG_DBNAME', 'template1')
    user = getenv('PG_USER', 'postgres')
    password = getenv('PG_PASSWORD', '')
    host = getenv('PG_HOST', '')
    port = int(getenv('PG_PORT', 0))
    selected_plugins = getenv('PG_MULTIGRAPHS', '__all__')
    selected_plugins = {name.strip() for name in selected_plugins.split(',')}

    available_plugins = PostgresPlugin.__subclasses__()
    if '__all__' in selected_plugins:
        active_plugins = available_plugins
    else:
        active_plugins = [plugin for plugin in available_plugins
                          if plugin.NAME in selected_plugins]

    connection = connect(construct_dsn(
        dbname,
        user,
        password,
        host,
        port))

    try:
        for cls in active_plugins:
            instance = cls(connection, user, password, host, port)
            if action == 'config':
                instance.config()
            else:
                instance.fetch()
    finally:
        connection.close()


if __name__ == '__main__':
    logging.basicConfig()
    args = parse_args()
    main(args.action)
